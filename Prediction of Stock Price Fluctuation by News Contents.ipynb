{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8e91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "###模型建立與資料處裡\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4177d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#每次只要跑一次就好\n",
    "#將dictionary改為個人工作路徑\n",
    "#讀資料\n",
    "raw_news = pd.read_csv('C:/dictionary/news.csv',encoding= 'big5')\n",
    "#第一表格: 上市2018\n",
    "stock_data = pd.read_excel('C:/dictionary/stock_data.xlsx',\n",
    "                           sheet_name = '上市2018')\n",
    "#第二表格: 上市2016\n",
    "stock_data2 = pd.read_excel('C:/dictionary/stock_data.xlsx',\n",
    "                           sheet_name = '上市2016')\n",
    "#第三表格: 上市2017\n",
    "stock_data3 = pd.read_excel('C:/dictionary/stock_data.xlsx',\n",
    "                           sheet_name = '上市2017')\n",
    "#合併df\n",
    "stock_data = pd.concat([stock_data,stock_data2,stock_data3],axis = 0)\n",
    "#重新排序\n",
    "stock_data = stock_data.sort_values(['年月日','證券代碼'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d7e461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     167754\n",
       "False     79519\n",
       "Name: post_time, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(raw_news['post_time'].str.contains('2018'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a9e444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    229312\n",
       "True      17961\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查詢新聞篇數\n",
    "pd.value_counts((raw_news['title'].str.contains('台積電')) | (raw_news['content'].str.contains('台積電') ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5665df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "###變數輸入\n",
    "stock_want_to_predict = '台積電'\n",
    "N_days_after = '3'\n",
    "percentage_threshold = 0.025 #預測漲跌門檻\n",
    "signal_mode = 2 #漲跌模式選擇 #1 收盤價對收盤價 #2 隔天開盤對 N天後最高\n",
    "tfidf_selection_mode = 3 #tfidf模式選擇 #1 tf前N名並取漲跌關鍵字差集 #2 tf-idf分數前N名並差集 #3 tf與卡方值均並列前N名並差集 \n",
    "tfidf_N_words = 10000 #詞向量變數個數\n",
    "vector_mode = 2  #詞向量模式選擇 #1 binary  #2 詞頻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ecdb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\1034110071.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  specific_stock_price['1dayaf_high'] = specific_stock_price['最高價(元)'].shift(-1)\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\1034110071.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  specific_stock_price['2dayaf_high'] = specific_stock_price['最高價(元)'].shift(-2)\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\1034110071.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  specific_stock_price['3dayaf_high'] = specific_stock_price['最高價(元)'].shift(-3)\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\1034110071.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  specific_stock_price['4dayaf_high'] = specific_stock_price['最高價(元)'].shift(-4)\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\1034110071.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  specific_stock_price['5dayaf_high'] = specific_stock_price['最高價(元)'].shift(-5)\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\1034110071.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  specific_stock_price['1dayaf_open'] = specific_stock_price['開盤價(元)'].shift(-1)\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\1034110071.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_stock['post_time'] = pd.to_datetime(news_stock['post_time'])\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\1034110071.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_stock['post_time'] = news_stock['post_time'].dt.strftime('%Y-%m-%d')\n"
     ]
    }
   ],
   "source": [
    "#########欲選擇股價篩出\n",
    "specific_stock_price = stock_data.loc[stock_data['證券代碼'].str.contains(stock_want_to_predict),:]\n",
    "\n",
    "#賦予漲跌指標\n",
    "#1天、2天、3天、4天、5天\n",
    "if signal_mode == 1:\n",
    "    specific_stock_price['1dayaf_close'] = specific_stock_price['收盤價(元)'].shift(-1)\n",
    "    specific_stock_price['2dayaf_close'] = specific_stock_price['收盤價(元)'].shift(-2)\n",
    "    specific_stock_price['3dayaf_close'] = specific_stock_price['收盤價(元)'].shift(-3)\n",
    "    specific_stock_price['4dayaf_close'] = specific_stock_price['收盤價(元)'].shift(-4)\n",
    "    specific_stock_price['5dayaf_close'] = specific_stock_price['收盤價(元)'].shift(-5)\n",
    "    specific_stock_price = specific_stock_price.iloc[:-5,:]\n",
    "\n",
    "    def get_sign(row,i):\n",
    "        if ((row[f'{i}dayaf_close']) - row['收盤價(元)']) /row['收盤價(元)'] >percentage_threshold:\n",
    "            return 'UP{}percent'.format(percentage_threshold*100)\n",
    "        elif ((row[f'{i}dayaf_close']) - row['收盤價(元)']) /row['收盤價(元)']< -percentage_threshold:\n",
    "            return 'DOWN{}percent'.format(percentage_threshold*100)\n",
    "        else:\n",
    "            return 'UNCHANGED'\n",
    "\n",
    "        \n",
    "    specific_stock_price['1dayaf_sign'] = specific_stock_price.apply(get_sign,i=1,axis = 1)\n",
    "    specific_stock_price['2dayaf_sign'] = specific_stock_price.apply(get_sign,i=2,axis = 1)\n",
    "    specific_stock_price['3dayaf_sign'] = specific_stock_price.apply(get_sign,i=3,axis = 1)\n",
    "    specific_stock_price['4dayaf_sign'] = specific_stock_price.apply(get_sign,i=4,axis = 1)\n",
    "    specific_stock_price['5dayaf_sign'] = specific_stock_price.apply(get_sign,i=5,axis = 1)    \n",
    "        \n",
    "        \n",
    "elif signal_mode == 2:\n",
    "    specific_stock_price['1dayaf_high'] = specific_stock_price['最高價(元)'].shift(-1)\n",
    "    specific_stock_price['2dayaf_high'] = specific_stock_price['最高價(元)'].shift(-2)\n",
    "    specific_stock_price['3dayaf_high'] = specific_stock_price['最高價(元)'].shift(-3)\n",
    "    specific_stock_price['4dayaf_high'] = specific_stock_price['最高價(元)'].shift(-4)\n",
    "    specific_stock_price['5dayaf_high'] = specific_stock_price['最高價(元)'].shift(-5)\n",
    "\n",
    "    specific_stock_price['1dayaf_open'] = specific_stock_price['開盤價(元)'].shift(-1)\n",
    "    \n",
    "    specific_stock_price = specific_stock_price.iloc[:-5,:]\n",
    "    \n",
    "    def get_sign(row,i):\n",
    "        if ((row[f'{i}dayaf_high']) - row['1dayaf_open']) /row['1dayaf_open'] >percentage_threshold:\n",
    "            return 'UP{}percent'.format(percentage_threshold*100)\n",
    "        elif ((row[f'{i}dayaf_high']) - row['1dayaf_open']) /row['1dayaf_open']< -percentage_threshold:\n",
    "            return 'DOWN{}percent'.format(percentage_threshold*100)\n",
    "        else:\n",
    "            return 'UNCHANGED'\n",
    "            return row.head()\n",
    "    \n",
    "    specific_stock_price['1dayaf_sign'] = specific_stock_price.apply(get_sign,i=1,axis = 1)\n",
    "    specific_stock_price['2dayaf_sign'] = specific_stock_price.apply(get_sign,i=2,axis = 1)\n",
    "    specific_stock_price['3dayaf_sign'] = specific_stock_price.apply(get_sign,i=3,axis = 1)\n",
    "    specific_stock_price['4dayaf_sign'] = specific_stock_price.apply(get_sign,i=4,axis = 1)\n",
    "    specific_stock_price['5dayaf_sign'] = specific_stock_price.apply(get_sign,i=5,axis = 1)\n",
    "else:\n",
    "    print('No this mode, following will go error')\n",
    "    \n",
    "    \n",
    "#########尋找欲選股票新聞\n",
    "news_stock = raw_news.loc[(raw_news['content'].str.contains(stock_want_to_predict)==True) | \n",
    "                          (raw_news['title'].str.contains(stock_want_to_predict)==True)  ,:]\n",
    "\n",
    "#結合漲跌指標與新聞\n",
    "#時間格式更改\n",
    "news_stock['post_time'].dtype\n",
    "news_stock['post_time'] = pd.to_datetime(news_stock['post_time'])\n",
    "# 使用 dt.strftime() 格式化日期时间\n",
    "news_stock['post_time'] = news_stock['post_time'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "specific_stock_price['年月日'] = pd.to_datetime(specific_stock_price['年月日'])\n",
    "# 使用 dt.strftime() 格式化日期时间\n",
    "specific_stock_price['年月日']= specific_stock_price['年月日'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "#針對不同天數進行新聞標註\n",
    "#選想要的天數\n",
    "news_for_stock_1 = pd.merge(news_stock,specific_stock_price.loc[:,['年月日','1dayaf_sign']],left_on= 'post_time', right_on= '年月日',\n",
    "                     how = 'right') \n",
    "news_for_stock_1 = news_for_stock_1.rename(columns={'1dayaf_sign': 'Ndayaf_sign'})\n",
    "\n",
    "news_for_stock_2 = pd.merge(news_stock,specific_stock_price.loc[:,['年月日','2dayaf_sign']],left_on= 'post_time', right_on= '年月日',\n",
    "                     how = 'right') \n",
    "news_for_stock_2 = news_for_stock_2.rename(columns={'2dayaf_sign': 'Ndayaf_sign'})\n",
    "\n",
    "news_for_stock_3 = pd.merge(news_stock,specific_stock_price.loc[:,['年月日','3dayaf_sign']],left_on= 'post_time', right_on= '年月日',\n",
    "                     how = 'right') \n",
    "news_for_stock_3 = news_for_stock_3.rename(columns={'3dayaf_sign': 'Ndayaf_sign'})\n",
    "\n",
    "news_for_stock_4 = pd.merge(news_stock,specific_stock_price.loc[:,['年月日','4dayaf_sign']],left_on= 'post_time', right_on= '年月日',\n",
    "                     how = 'right') \n",
    "news_for_stock_4 = news_for_stock_4.rename(columns={'4dayaf_sign': 'Ndayaf_sign'})\n",
    "\n",
    "news_for_stock_5 = pd.merge(news_stock,specific_stock_price.loc[:,['年月日','5dayaf_sign']],left_on= 'post_time', right_on= '年月日',\n",
    "                     how = 'right') \n",
    "news_for_stock_5 = news_for_stock_5.rename(columns={'5dayaf_sign': 'Ndayaf_sign'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e854f77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新聞標籤分布數量\n",
      " UNCHANGED         13571\n",
      "UP2.5percent       2678\n",
      "DOWN2.5percent      629\n",
      "Name: Ndayaf_sign, dtype: int64\n",
      "股票漲跌日數分布\n",
      " UNCHANGED         593\n",
      "UP2.5percent      115\n",
      "DOWN2.5percent     24\n",
      "Name: 3dayaf_sign, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#變數命名\n",
    "news_variable_name = \"news_for_stock_{}\".format(N_days_after)\n",
    "news = locals()[news_variable_name]\n",
    "news = news.loc[news['id'].isna()==False,:]\n",
    "print('新聞標籤分布數量\\n',pd.value_counts(news['Ndayaf_sign']))\n",
    "print('股票漲跌日數分布\\n',pd.value_counts(specific_stock_price['{}dayaf_sign'.format(N_days_after)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd55b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_news: 13502 test_news: 3376\n",
      "train_news有漲跌: 2628 test_news有漲跌: 679\n",
      "train_news_UP資料筆數: 2140 train_news_DOWN資料筆數: 488\n"
     ]
    }
   ],
   "source": [
    "#將新聞區分成訓練資料與測試資料 - 全部進行訓練\n",
    "train_news = news.sample(frac=0.8, random_state=42)\n",
    "test_news = news.drop(train_news.index)\n",
    "print('train_news:',len(train_news),'test_news:',len(test_news))\n",
    "print('train_news有漲跌:',len(train_news[train_news['Ndayaf_sign']!='UNCHANGED']),'test_news有漲跌:',\n",
    "      len(test_news[test_news['Ndayaf_sign']!='UNCHANGED']))\n",
    "\n",
    "\n",
    "#將訓練新聞拆分為漲資料集與跌資料集\n",
    "train_news_UP = train_news.loc[news['Ndayaf_sign'] == 'UP{}percent'.format(percentage_threshold*100),:]\n",
    "train_news_DOWN = train_news.loc[news['Ndayaf_sign'] == 'DOWN{}percent'.format(percentage_threshold*100),:]\n",
    "print('train_news_UP資料筆數:',len(train_news_UP),'train_news_DOWN資料筆數:',len(train_news_DOWN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85328ebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#要處裡空值行，不然preprocess_text會出錯\n",
    "#將float型態轉為string\n",
    "train_news_UP = train_news_UP.loc[train_news_UP['id'].isna()==False,:]\n",
    "train_news_UP['content'] = train_news_UP['content'].astype(str)\n",
    "\n",
    "# stop words\n",
    "stop_words =set( [\n",
    "    \"的\", \"了\", \"和\", \"是\", \"在\", \"他\", \"她\", \"它\", \"我\", \"你\",\n",
    "    \"我們\", \"你們\", \"他們\", \"她們\", \"它們\", \"這\", \"那\", \"這個\", \"那個\", \n",
    "    \"就是\", \"就\", \"吧\", \"呢\", \"啊\", \"哦\", \"哈\", \"哈哈\", \"嗯\", \"嗯嗯\",\n",
    "    \"的話\", \"如果\", \"因為\", \"所以\", \"然後\", \"但是\", \"而且\", \"或者\", \"而是\",\n",
    "    \"因此\", \"雖然\", \"但\", \"和\", \"與\", \"等\", \"及\", \"及其\", \"等等\", \"等等等\",\n",
    "    \"這樣\", \"那樣\", \"這裡\", \"那裡\", \"這兒\", \"那兒\", \"這裡面\", \"那裡面\",\n",
    "    \"這個時候\", \"那個時候\", \"現在\", \"以前\", \"以後\", \"一直\", \"一般\", \"通常\",\n",
    "    \"總是\", \"有時候\", \"有的時候\", \"有時\", \"有的時\", \"有的\", \"一些\", \"一般來說\",\n",
    "    \"總的來說\", \"總的說來\", \"總的來看\", \"因為這樣\", \"因為那樣\", \"例如\", \"譬如\",\n",
    "    \"比如\", \"不過\", \"可是\", \"然而\", \"但是\", \"不過\", \"卻\", \"只是\", \"只不過\",\n",
    "    \"不僅\", \"而且\", \"只有\", \"唯有\", \"不是\", \"不是因為\", \"不是因為而\", \"只有\",\n",
    "    \"僅僅\", \"只不過\", \"只要\", \"只需\", \"只有\", \"只是\", \"隨著\", \"就是說\", \"對於\",\n",
    "    \"對於這\", \"對於那\", \"對\", \"對了\", \"對的\", \"有\", \"沒有\", \"是不是\", \"是否\",\n",
    "    \"就是說\", \"就是了\", \"就是的\", \"就是\", \"一般來說\", \"總的說來\",\n",
    "    # 常見的標點符號\n",
    "    \"。\", \"，\", \"！\", \"？\", \"：\", \"；\", \"（\", \"）\", \"&#8203;``【oaicite:0】``&#8203;\", \"《\", \"》\", \"「\", \"」\", \"『\", \"』\"\n",
    "    # ... 其他可能的停用詞\n",
    "])\n",
    "\n",
    "# 定義前處理公式\n",
    "def preprocess_text(text):\n",
    "    # 使用正則表達式刪除數字與英文\n",
    "    text = re.sub(r'[0-9a-zA-Z]', '', text)\n",
    "    # 使用 jieba 分詞並過濾掉停用詞\n",
    "    words = [word for word in jieba.cut(text) if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab3ee060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\shawn\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.410 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index     tf-idf  類別df  全部df  chi-square\n",
      "0       台積電  14.444456   332  1793    0.002692\n",
      "1        台股  13.309319   267  1542    1.305990\n",
      "2        指數  12.902290   242  1446    2.617599\n",
      "3        億元  12.288427   252  1428    0.654003\n",
      "4        外資   9.757621   193  1106    0.745775\n",
      "...     ...        ...   ...   ...         ...\n",
      "14175    稱其   0.058460     1     2    1.064008\n",
      "14176    量化   0.058460     1     4    0.089082\n",
      "14177    現好   0.058460     1     1    3.570938\n",
      "14178    工資   0.058460     1     2    1.064008\n",
      "14179    蓄率   0.058460     1     1    3.570938\n",
      "\n",
      "[14180 rows x 5 columns]\n",
      "      index     tf-idf  類別df  全部df  chi-square\n",
      "0       台積電  58.612336  1461  1793    0.000614\n",
      "1        台股  58.081008  1275  1542    0.297814\n",
      "2        指數  56.649777  1204  1446    0.596910\n",
      "3        億元  51.947262  1176  1428    0.149137\n",
      "4        市場  41.284974  1063  1278    0.478495\n",
      "...     ...        ...   ...   ...         ...\n",
      "37611   移民法   0.040690     1     1    0.042345\n",
      "37612   強貿易   0.040690     1     1    0.042345\n",
      "37613   以亞洲   0.040690     1     1    0.042345\n",
      "37614    城示   0.040690     1     1    0.042345\n",
      "37615    積約   0.040690     1     1    0.042345\n",
      "\n",
      "[37616 rows x 5 columns]\n",
      "跌關鍵字: 0         條約\n",
      "1         中程\n",
      "2         軍演\n",
      "3        潤泰材\n",
      "4         海峽\n",
      "        ... \n",
      "6923      短空\n",
      "6924     觀察到\n",
      "6925      一早\n",
      "6926      內閣\n",
      "6927    盤後股價\n",
      "Name: index, Length: 6928, dtype: object\n",
      "漲關鍵字: 0         軍演\n",
      "1         台海\n",
      "2        以光電\n",
      "3         緊張\n",
      "4         除息\n",
      "        ... \n",
      "6743      最遲\n",
      "6744     陸售價\n",
      "6745      微降\n",
      "6746     富邦售\n",
      "6747    隨後拉回\n",
      "Name: index, Length: 6748, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##先處裡過，變數一開始就能使用2、3 \n",
    "# 對'content' 列進行前處理\n",
    "train_news_UP = train_news_UP.loc[train_news_UP['id'].isna()==False,:]\n",
    "train_news_UP['content'] = train_news_UP['content'].astype(str)\n",
    "train_news_UP['processed_content'] = train_news_UP['content'].apply(preprocess_text)\n",
    "\n",
    "# 获取处理后的文本数据\n",
    "corpus_up = train_news_UP['processed_content'].tolist()\n",
    "\n",
    "# 使用 TfidfVectorizer 進行 TF-IDF 分析\n",
    "vectorizer_u = TfidfVectorizer(max_features = tfidf_N_words)  # 選擇前N個重要的特徵\n",
    "tfidf_matrix_u = vectorizer_u.fit_transform(corpus_up)\n",
    "\n",
    "# 獲取特徵名字列表\n",
    "feature_names_u = vectorizer_u.get_feature_names_out()\n",
    "\n",
    "# 創建 DataFrame\n",
    "df_tfidf_u = pd.DataFrame(data=tfidf_matrix_u.toarray(), columns=feature_names_u)\n",
    "\n",
    "# 計算每一列（詞彙）的 TF-IDF 分數之和，並根據這個總和降序排序\n",
    "df_tfidf_sorted_u = df_tfidf_u.T.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "# 將排序後的詞彙索引取出\n",
    "sorted_feature_indices_u = df_tfidf_sorted_u.index\n",
    "\n",
    "# 根據排序後的詞彙索引重新排序 DataFrame\n",
    "df_tfidf_sorted_u = df_tfidf_u[sorted_feature_indices_u]\n",
    "\n",
    "#總和\n",
    "# 對每一列計算總和\n",
    "column_sum_u = df_tfidf_sorted_u.sum(axis=0)\n",
    "df_tfidf_total_u = pd.DataFrame(column_sum_u, columns=['tf-idf'])\n",
    "\n",
    "df_tfidf_total_u = df_tfidf_total_u.reset_index(drop = False)\n",
    "# 顯示列總和\n",
    "#print(df_tfidf_total.sort_values)\n",
    "#df_tfidf_total.to_csv('df_tfidf_total.csv', index=True,encoding='utf-8')\n",
    "\n",
    "\n",
    "#要處裡空值行，不然preprocess_text會出錯\n",
    "train_news_DOWN = train_news_DOWN.loc[train_news_DOWN['id'].isna()==False,:]\n",
    "train_news_DOWN['content'] = train_news_DOWN['content'].astype(str)\n",
    "\n",
    "#改對下跌的文章進行處理\n",
    "\n",
    "# 對'content' 列進行前處理\n",
    "train_news_DOWN['processed_content'] = train_news_DOWN['content'].apply(preprocess_text)\n",
    "\n",
    "# 获取处理后的文本数据\n",
    "corpus_d = train_news_DOWN['processed_content'].tolist()\n",
    "\n",
    "\n",
    "#使用 TfidfVectorizer 進行 TF-IDF 分析\n",
    "vectorizer_d = TfidfVectorizer(max_features = tfidf_N_words)  # 選擇前N個重要的特徵\n",
    "tfidf_matrix_d = vectorizer_d.fit_transform(corpus_d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 獲取特徵名字列表\n",
    "feature_names_d = vectorizer_d.get_feature_names_out()\n",
    "\n",
    "# 創建 DataFrame\n",
    "df_tfidf_d = pd.DataFrame(data=tfidf_matrix_d.toarray(), columns=feature_names_d)\n",
    "\n",
    "# 計算每一列（詞彙）的 TF-IDF 分數之和，並根據這個總和降序排序\n",
    "df_tfidf_sorted_d = df_tfidf_d.T.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "# 將排序後的詞彙索引取出\n",
    "sorted_feature_indices_d = df_tfidf_sorted_d.index\n",
    "\n",
    "# 根據排序後的詞彙索引重新排序 DataFrame\n",
    "df_tfidf_sorted_d = df_tfidf_d[sorted_feature_indices_d]\n",
    "\n",
    "#總和\n",
    "# 對每一列計算總和\n",
    "column_sum_d = df_tfidf_sorted_d.sum(axis=0)\n",
    "df_tfidf_total_d = pd.DataFrame(column_sum_d, columns=['tf-idf'])\n",
    "\n",
    "df_tfidf_total_d = df_tfidf_total_d.reset_index(drop = False)\n",
    "# 顯示列總和\n",
    "#print(df_tfidf_total_d.sort_values)\n",
    "df_tfidf_total_d.to_csv('df_tfidf_total_d.csv', index=True,encoding='utf-8')\n",
    "\n",
    "#上漲下跌顯著詞彙\n",
    "#篩選邏輯: tf-idf 各自前600名沒有出現在另外一個集合當中的詞彙\n",
    "key_words_Down = list(set(df_tfidf_total_d['index']) - set(df_tfidf_total_u['index']))\n",
    "key_words_Up = list(set(df_tfidf_total_u['index']) - set(df_tfidf_total_d['index']))\n",
    "    \n",
    "    \n",
    "if tfidf_selection_mode == 1:\n",
    "    ##選擇tf前N名並差集\n",
    "    \n",
    "    # 對'content' 列進行前處理\n",
    "    train_news_UP = train_news_UP.loc[train_news_UP['id'].isna()==False,:]\n",
    "    train_news_UP['content'] = train_news_UP['content'].astype(str)\n",
    "    train_news_UP['processed_content'] = train_news_UP['content'].apply(preprocess_text)\n",
    "\n",
    "    # 获取处理后的文本数据\n",
    "    corpus_up = train_news_UP['processed_content'].tolist()\n",
    "\n",
    "    # 使用 TfidfVectorizer 進行 TF-IDF 分析\n",
    "    vectorizer_u = TfidfVectorizer(max_features = tfidf_N_words)  # 選擇前N個重要的特徵\n",
    "    tfidf_matrix_u = vectorizer_u.fit_transform(corpus_up)\n",
    "\n",
    "    # 獲取特徵名字列表\n",
    "    feature_names_u = vectorizer_u.get_feature_names_out()\n",
    "\n",
    "    # 創建 DataFrame\n",
    "    df_tfidf_u = pd.DataFrame(data=tfidf_matrix_u.toarray(), columns=feature_names_u)\n",
    "\n",
    "    # 計算每一列（詞彙）的 TF-IDF 分數之和，並根據這個總和降序排序\n",
    "    df_tfidf_sorted_u = df_tfidf_u.T.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "    # 將排序後的詞彙索引取出\n",
    "    sorted_feature_indices_u = df_tfidf_sorted_u.index\n",
    "\n",
    "    # 根據排序後的詞彙索引重新排序 DataFrame\n",
    "    df_tfidf_sorted_u = df_tfidf_u[sorted_feature_indices_u]\n",
    "\n",
    "    #總和\n",
    "    # 對每一列計算總和\n",
    "    column_sum_u = df_tfidf_sorted_u.sum(axis=0)\n",
    "    df_tfidf_total_u = pd.DataFrame(column_sum_u, columns=['tf-idf'])\n",
    "\n",
    "    df_tfidf_total_u = df_tfidf_total_u.reset_index(drop = False)\n",
    "    # 顯示列總和\n",
    "    #print(df_tfidf_total.sort_values)\n",
    "    #df_tfidf_total.to_csv('df_tfidf_total.csv', index=True,encoding='utf-8')\n",
    "\n",
    "\n",
    "    #要處裡空值行，不然preprocess_text會出錯\n",
    "    train_news_DOWN = train_news_DOWN.loc[train_news_DOWN['id'].isna()==False,:]\n",
    "    train_news_DOWN['content'] = train_news_DOWN['content'].astype(str)\n",
    "\n",
    "    #改對下跌的文章進行處理\n",
    "\n",
    "    # 對'content' 列進行前處理\n",
    "    train_news_DOWN['processed_content'] = train_news_DOWN['content'].apply(preprocess_text)\n",
    "\n",
    "    # 获取处理后的文本数据\n",
    "    corpus_d = train_news_DOWN['processed_content'].tolist()\n",
    "\n",
    "\n",
    "    #使用 TfidfVectorizer 進行 TF-IDF 分析\n",
    "    vectorizer_d = TfidfVectorizer(max_features = tfidf_N_words)  # 選擇前N個重要的特徵\n",
    "    tfidf_matrix_d = vectorizer_d.fit_transform(corpus_d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 獲取特徵名字列表\n",
    "    feature_names_d = vectorizer_d.get_feature_names_out()\n",
    "\n",
    "    # 創建 DataFrame\n",
    "    df_tfidf_d = pd.DataFrame(data=tfidf_matrix_d.toarray(), columns=feature_names_d)\n",
    "\n",
    "    # 計算每一列（詞彙）的 TF-IDF 分數之和，並根據這個總和降序排序\n",
    "    df_tfidf_sorted_d = df_tfidf_d.T.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "    # 將排序後的詞彙索引取出\n",
    "    sorted_feature_indices_d = df_tfidf_sorted_d.index\n",
    "\n",
    "    # 根據排序後的詞彙索引重新排序 DataFrame\n",
    "    df_tfidf_sorted_d = df_tfidf_d[sorted_feature_indices_d]\n",
    "\n",
    "    #總和\n",
    "    # 對每一列計算總和\n",
    "    column_sum_d = df_tfidf_sorted_d.sum(axis=0)\n",
    "    df_tfidf_total_d = pd.DataFrame(column_sum_d, columns=['tf-idf'])\n",
    "\n",
    "    df_tfidf_total_d = df_tfidf_total_d.reset_index(drop = False)\n",
    "    # 顯示列總和\n",
    "    #print(df_tfidf_total_d.sort_values)\n",
    "    df_tfidf_total_d.to_csv('df_tfidf_total_d.csv', index=True,encoding='utf-8')\n",
    "\n",
    "    #上漲下跌顯著詞彙\n",
    "    #篩選邏輯: tf-idf 各自前600名沒有出現在另外一個集合當中的詞彙\n",
    "    key_words_Down = list(set(df_tfidf_total_d['index']) - set(df_tfidf_total_u['index']))\n",
    "    key_words_Up = list(set(df_tfidf_total_u['index']) - set(df_tfidf_total_d['index']))\n",
    "    print('up',len(key_words_Up),key_words_Up, 'down:',len(key_words_Down),key_words_Down)\n",
    "\n",
    "elif tfidf_selection_mode == 2:\n",
    "    ##使用tf-idf重要前N名並且差集\n",
    "    #UP\n",
    "    # 使用 TfidfVectorizer 計算 TF-IDF\n",
    "    vectorizer_u = TfidfVectorizer(sublinear_tf = True)\n",
    "    tfidf_matrix_u = vectorizer_u.fit_transform(corpus_up)\n",
    "\n",
    "    # 獲取特徵詞彙表和對應的 TF-IDF 分數\n",
    "    feature_names_u = vectorizer_u.get_feature_names_out()\n",
    "    tfidf_scores_u = tfidf_matrix_u.max(axis=0).toarray()[0]\n",
    "\n",
    "\n",
    "    # 將特徵和對應的 TF-IDF 分数组合成 DataFrame\n",
    "    df_tfidf_u = pd.DataFrame({'feature': feature_names_u, 'tf-idf': tfidf_scores_u})\n",
    "\n",
    "    # 按照 TF-IDF 分數進行排序\n",
    "    df_tfidf_sorted_u = df_tfidf_u.sort_values(by='tf-idf', ascending=False)\n",
    "\n",
    "    # 選擇前 N 個特徵\n",
    "    selected_features_u = df_tfidf_sorted_u.head( tfidf_N_words )['feature'].tolist()\n",
    "\n",
    "\n",
    "    #DOWN\n",
    "    # 使用 TfidfVectorizer 計算 TF-IDF\n",
    "    vectorizer_d = TfidfVectorizer(sublinear_tf = True)\n",
    "    tfidf_matrix_d = vectorizer_d.fit_transform(corpus_d)\n",
    "\n",
    "    # 獲取特徵詞彙表和對應的 TF-IDF 分數\n",
    "    feature_names_d = vectorizer_d.get_feature_names_out()\n",
    "    tfidf_scores_d = tfidf_matrix_d.max(axis=0).toarray()[0]\n",
    "\n",
    "    # 將特徵和對應的 TF-IDF 分数组合成 DataFrame\n",
    "    df_tfidf_d = pd.DataFrame({'feature': feature_names_d, 'tf-idf': tfidf_scores_d})\n",
    "\n",
    "    # 按照 TF-IDF 分數進行排序\n",
    "    df_tfidf_sorted_d = df_tfidf_d.sort_values(by='tf-idf', ascending=False)\n",
    "\n",
    "    # 選擇前 1500 個特徵\n",
    "    selected_features_d = df_tfidf_sorted_d.head( tfidf_N_words )['feature'].tolist()\n",
    "\n",
    "\n",
    "    #篩出詞彙差集\n",
    "    key_words_Down = list(set(selected_features_d) - set(selected_features_u))\n",
    "    key_words_Up = list(set(selected_features_u) - set(selected_features_d))\n",
    "    print('up',len(key_words_Up),key_words_Up, 'down:',len(key_words_Down),key_words_Down)\n",
    "\n",
    "else:\n",
    "    ###加入卡方值來選取詞彙\n",
    "    ##DOWN\n",
    "    # 使用 TfidfVectorizer 進行 TF-IDF 分析\n",
    "    vectorizer_d = TfidfVectorizer(sublinear_tf = True)  \n",
    "    tfidf_matrix_d = vectorizer_d.fit_transform(corpus_d)\n",
    "    # 獲取特徵名字列表\n",
    "    feature_names_d = vectorizer_d.get_feature_names_out()\n",
    "\n",
    "    # 創建 DataFrame\n",
    "    df_tfidf_d = pd.DataFrame(data=tfidf_matrix_d.toarray(), columns=feature_names_d)\n",
    "\n",
    "    # 計算每一列（詞彙）的 TF-IDF 分數之和，並根據這個總和降序排序\n",
    "    df_tfidf_sorted_d = df_tfidf_d.T.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "    # 將排序後的詞彙索引取出\n",
    "    sorted_feature_indices_d = df_tfidf_sorted_d.index\n",
    "\n",
    "    # 根據排序後的詞彙索引重新排序 DataFrame\n",
    "    df_tfidf_sorted_d = df_tfidf_d[sorted_feature_indices_d]\n",
    "    #總和\n",
    "    # 對每一列計算總和\n",
    "    column_sum_d = df_tfidf_sorted_d.sum(axis=0)\n",
    "    df_tfidf_total_d = pd.DataFrame(column_sum_d, columns=['tf-idf'])\n",
    "\n",
    "    df_tfidf_total_d = df_tfidf_total_d.reset_index(drop = False)\n",
    "\n",
    "    #類別中down df \n",
    "    df_tfidf_total_d['類別df'] = (df_tfidf_sorted_d.T>0).sum(axis=1).to_list()\n",
    "    key_words_Down = df_tfidf_total_d['index']\n",
    "\n",
    "\n",
    "    ##UP\n",
    "    # 使用 TfidfVectorizer 進行 TF-IDF 分析\n",
    "    vectorizer_u = TfidfVectorizer(sublinear_tf = True)  \n",
    "    tfidf_matrix_u = vectorizer_u.fit_transform(corpus_up)\n",
    "\n",
    "    # 獲取特徵名字列表\n",
    "    feature_names_u = vectorizer_u.get_feature_names_out()\n",
    "\n",
    "    # 創建 DataFrame\n",
    "    df_tfidf_u = pd.DataFrame(data=tfidf_matrix_u.toarray(), columns=feature_names_u)\n",
    "\n",
    "    # 計算每一列（詞彙）的 TF-IDF 分數之和，並根據這個總和降序排序\n",
    "    df_tfidf_sorted_u = df_tfidf_u.T.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "    # 將排序後的詞彙索引取出\n",
    "    sorted_feature_indices_u = df_tfidf_sorted_u.index\n",
    "\n",
    "    # 根據排序後的詞彙索引重新排序 DataFrame\n",
    "    df_tfidf_sorted_u = df_tfidf_u[sorted_feature_indices_u]\n",
    "\n",
    "    #總和\n",
    "    # 對每一列計算總和\n",
    "    column_sum_u = df_tfidf_sorted_u.sum(axis=0)\n",
    "    df_tfidf_total_u = pd.DataFrame(column_sum_u, columns=['tf-idf'])\n",
    "\n",
    "    df_tfidf_total_u = df_tfidf_total_u.reset_index(drop = False)\n",
    "\n",
    "    #類別中up df \n",
    "    df_tfidf_total_u['類別df'] = (df_tfidf_sorted_u.T>0).sum(axis=1).to_list()\n",
    "    key_words_Up = df_tfidf_total_u['index']\n",
    "\n",
    "    ###全df\n",
    "    df_tfidf_total_d['index']\n",
    "    corpus = corpus_up + corpus_d\n",
    "    keywords = set(key_words_Up.to_list()+key_words_Down.to_list())\n",
    "\n",
    "    # 使用 TfidfVectorizer 進行 TF-IDF 分析\n",
    "    vectorizer = TfidfVectorizer(vocabulary= keywords)  \n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # 獲取特徵名字列表\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # 創建 DataFrame\n",
    "    df_tfidf = pd.DataFrame(data=tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "    # 計算每一列（詞彙）的 TF-IDF 分數之和，並根據這個總和降序排序\n",
    "    df_tfidf_sorted = df_tfidf.T.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "    # 將排序後的詞彙索引取出\n",
    "    sorted_feature_indices = df_tfidf_sorted.index\n",
    "\n",
    "    # 根據排序後的詞彙索引重新排序 DataFrame\n",
    "    df_tfidf_sorted = df_tfidf[sorted_feature_indices]\n",
    "\n",
    "    #計算總df\n",
    "    total_df = pd.DataFrame((df_tfidf_sorted.T>0).sum(axis=1),columns = ['全部df']).reset_index()\n",
    "\n",
    "    #for down\n",
    "    df_tfidf_total_d = pd.merge(df_tfidf_total_d,total_df.loc[:,['index','全部df']], on ='index', how = 'left')\n",
    "    Expected_df_d =  (df_tfidf_total_d['全部df']/len(corpus)) * len(corpus_d)\n",
    "    Observed_df_d = df_tfidf_total_d['類別df'] \n",
    "    df_tfidf_total_d['chi-square'] = ((( Observed_df_d - Expected_df_d )**2)/Expected_df_d)\n",
    "    print(df_tfidf_total_d)\n",
    "\n",
    "    #for up\n",
    "    df_tfidf_total_u = pd.merge(df_tfidf_total_u,total_df.loc[:,['index','全部df']], on ='index', how = 'left')\n",
    "    Expected_df_u =  (df_tfidf_total_u['全部df']/len(corpus)) * len(corpus_up)\n",
    "    Observed_df_u = df_tfidf_total_u['類別df'] \n",
    "    df_tfidf_total_u['chi-square'] = ((( Observed_df_u - Expected_df_u )**2)/Expected_df_u)\n",
    "    print(df_tfidf_total_u)\n",
    "\n",
    "\n",
    "    ###挑選詞彙\n",
    "    #chi-square 前 N 名且 tf-idf也前 N 名的詞彙\n",
    "\n",
    "    #down\n",
    "    top_chi_square_d = df_tfidf_total_d.nlargest(tfidf_N_words,'chi-square')\n",
    "    top_tfidf_d = df_tfidf_total_d.nlargest(tfidf_N_words, 'tf-idf')\n",
    "    top_combined_d = pd.merge(top_chi_square_d, top_tfidf_d, on='index')\n",
    "    print( '跌關鍵字:' , top_combined_d['index'])\n",
    "    key_words_Down = top_combined_d['index']\n",
    "    #up\n",
    "    top_chi_square_u = df_tfidf_total_u.nlargest(tfidf_N_words,'chi-square')\n",
    "    top_tfidf_u = df_tfidf_total_u.nlargest(tfidf_N_words, 'tf-idf')\n",
    "    top_combined_u = pd.merge(top_chi_square_u, top_tfidf_u, on='index')\n",
    "    key_words_Up = top_combined_u['index']\n",
    "    print( '漲關鍵字:' , top_combined_u['index'])\n",
    "\n",
    "    key_words_Down = list(set(top_combined_d['index']) - set(top_combined_u['index']))\n",
    "    key_words_Up = list(set(top_combined_u['index']) - set(top_combined_d['index']))\n",
    "\n",
    "\n",
    "#pd.DataFrame(key_words_Down).to_csv('key_words_Down.csv', index=True,encoding='utf-8')\n",
    "#pd.DataFrame(key_words_Up).to_csv('key_words_Up.csv', index=True,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1179fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特定詞彙卡方值: 271    2.459466\n",
      "Name: chi-square, dtype: float64\n",
      "\n",
      "chisquare 分布:\n",
      " True     8695\n",
      "False    5485\n",
      "Name: chi-square, dtype: int64\n",
      "\n",
      "key_words_Down長度: 3962\n",
      "key_words_Up長度: 3782\n"
     ]
    }
   ],
   "source": [
    "#查詢特定詞彙卡方值\n",
    "print('特定詞彙卡方值:',df_tfidf_total_d.loc[df_tfidf_total_d['index']== '投資人','chi-square'])\n",
    "\n",
    "#查看 chisquare 分布\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "print('\\nchisquare 分布:\\n',pd.value_counts(df_tfidf_total_d.sort_values('chi-square',ascending= False)['chi-square']>1))\n",
    "\n",
    "#查看 keywords長度\n",
    "print('\\nkey_words_Down長度:',len(key_words_Down))\n",
    "print('key_words_Up長度:',len(key_words_Up))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10c9873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       軍備  日加權  將與會  靠奈米  突發  急升  美中爭  營收表現  風國際  為點  ...  關心  帶動華新  還重  台燿大漲  \\\n",
      "0       0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "1       0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "2       0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "3       0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "4       0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "...    ..  ...  ...  ...  ..  ..  ...   ...  ...  ..  ...  ..   ...  ..   ...   \n",
      "13497   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "13498   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "13499   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "13500   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "13501   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "\n",
      "       投信將  外傳  地震  華碩漲  大勝  遍野  \n",
      "0        0   0   0    0   0   0  \n",
      "1        0   0   0    0   0   0  \n",
      "2        0   0   0    0   0   0  \n",
      "3        0   0   0    0   0   0  \n",
      "4        0   0   0    0   0   0  \n",
      "...    ...  ..  ..  ...  ..  ..  \n",
      "13497    0   0   0    0   0   0  \n",
      "13498    0   0   0    0   0   0  \n",
      "13499    0   0   0    0   1   0  \n",
      "13500    0   0   0    0   0   0  \n",
      "13501    0   0   0    0   0   0  \n",
      "\n",
      "[13502 rows x 7744 columns]\n",
      "訓練新聞-漲跌新聞比例\n",
      " 0    13495\n",
      "1        6\n",
      "2        1\n",
      "Name: 軍備, dtype: int64\n",
      "      軍備  日加權  將與會  靠奈米  突發  急升  美中爭  營收表現  風國際  為點  ...  關心  帶動華新  還重  台燿大漲  \\\n",
      "0      0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "1      0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "2      0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "3      0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "4      0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "...   ..  ...  ...  ...  ..  ..  ...   ...  ...  ..  ...  ..   ...  ..   ...   \n",
      "3371   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "3372   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "3373   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "3374   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "3375   0    0    0    0   0   0    0     0    0   0  ...   0     0   0     0   \n",
      "\n",
      "      投信將  外傳  地震  華碩漲  大勝  遍野  \n",
      "0       0   0   0    0   0   0  \n",
      "1       0   0   0    0   0   0  \n",
      "2       0   0   0    0   0   0  \n",
      "3       0   0   0    0   0   1  \n",
      "4       0   0   0    0   0   0  \n",
      "...   ...  ..  ..  ...  ..  ..  \n",
      "3371    0   0   0    0   0   0  \n",
      "3372    0   0   0    0   0   0  \n",
      "3373    0   0   0    0   0   0  \n",
      "3374    0   0   0    0   0   0  \n",
      "3375    0   0   0    0   0   0  \n",
      "\n",
      "[3376 rows x 7744 columns]\n",
      "測試新聞-漲跌新聞比例\n",
      " 0    3374\n",
      "1       1\n",
      "2       1\n",
      "Name: 軍備, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if vector_mode == 1:\n",
    "\n",
    "    # 使用 TfidfVectorizer\n",
    "    # TfidfVectorizer裡面 use_idf and norm 要記得設定，不然只是tf binary 不是整個output\n",
    "    #使用訓練新聞集建立訓練矩陣\n",
    "\n",
    "    #對'content' 列進行前處理\n",
    "    train_news['processed_content'] = train_news['content'].astype(str).apply(preprocess_text)\n",
    "\n",
    "    corpus = train_news['processed_content'].tolist()\n",
    "\n",
    "    keywords = list(set(key_words_Up+key_words_Down))\n",
    "    vectorizer = TfidfVectorizer(vocabulary=keywords, binary=True,use_idf = False,norm = None) \n",
    "\n",
    "\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # 將 tfidf_matrix 轉換為 DataFrame\n",
    "    df_wv_space_train = pd.DataFrame(data=tfidf_matrix.toarray(), columns=keywords)\n",
    "    df_wv_space_train = df_wv_space_train.astype(int)\n",
    "    # 顯示結果\n",
    "    print(df_wv_space_train)\n",
    "\n",
    "\n",
    "    #顯示漲跌新聞比例\n",
    "    print('訓練新聞-漲跌新聞比例\\n',pd.value_counts(df_wv_space_train.iloc[:,0]))\n",
    "\n",
    "    #加上漲跌標籤\n",
    "    #3天後股價上漲下跌超過2.5%\n",
    "    df_wv_space_train['Ndayaf_sign'] = train_news['Ndayaf_sign'].to_list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #使用測試新聞集建立測試矩陣\n",
    "    #對'content' 列進行前處理\n",
    "    test_news['processed_content'] = test_news['content'].astype(str).apply(preprocess_text)\n",
    "\n",
    "    corpus = test_news['processed_content'].tolist()\n",
    "    keywords = list(set(key_words_Up+key_words_Down))\n",
    "    vectorizer = TfidfVectorizer(vocabulary=keywords, binary=True,use_idf = False,norm = None) \n",
    "\n",
    "\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # 將 tfidf_matrix 轉換為 DataFrame\n",
    "    df_wv_space_test = pd.DataFrame(data=tfidf_matrix.toarray(), columns=keywords)\n",
    "    df_wv_space_test = df_wv_space_test.astype(int)\n",
    "    # 顯示結果\n",
    "    print(df_wv_space_test)\n",
    "\n",
    "\n",
    "    #顯示漲跌新聞比例\n",
    "    print('測試新聞-漲跌新聞比例\\n',pd.value_counts(df_wv_space_test.iloc[:,0]))\n",
    "\n",
    "    #加上漲跌標籤\n",
    "    #3天後股價上漲下跌超過2.5%\n",
    "\n",
    "    df_wv_space_test['Ndayaf_sign'] = test_news['Ndayaf_sign'].to_list()\n",
    "\n",
    "\n",
    "    #匯出csv\n",
    "    #df_wv_space_test.to_csv('df_wv_space_test.csv', index=True,encoding='utf-8')\n",
    "    \n",
    "elif vector_mode == 2:\n",
    "    # 使用 TfidfVectorizer\n",
    "    # TfidfVectorizer裡面 use_idf and norm 要記得設定，不然只是tf binary 不是整個output\n",
    "    #使用訓練新聞集建立訓練矩陣\n",
    "\n",
    "    #對'content' 列進行前處理\n",
    "    train_news['processed_content'] = train_news['content'].astype(str).apply(preprocess_text)\n",
    "\n",
    "    corpus = train_news['processed_content'].tolist()\n",
    "\n",
    "    keywords = list(set(key_words_Up+key_words_Down))\n",
    "    count_vectorizer = CountVectorizer(vocabulary=keywords)\n",
    "\n",
    "    tfidf_matrix = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # 將 tfidf_matrix 轉換為 DataFrame\n",
    "    df_wv_space_train = pd.DataFrame(data=tfidf_matrix.toarray(), columns=keywords)\n",
    "    df_wv_space_train = df_wv_space_train.astype(int)\n",
    "    # 顯示結果\n",
    "    print(df_wv_space_train)\n",
    "\n",
    "\n",
    "    #顯示漲跌新聞比例\n",
    "    print('訓練新聞-漲跌新聞比例\\n',pd.value_counts(df_wv_space_train.iloc[:,0]))\n",
    "\n",
    "    #加上漲跌標籤\n",
    "    #3天後股價上漲下跌超過2.5%\n",
    "    df_wv_space_train['Ndayaf_sign'] = train_news['Ndayaf_sign'].to_list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #使用測試新聞集建立測試矩陣\n",
    "    #對'content' 列進行前處理\n",
    "    test_news['processed_content'] = test_news['content'].astype(str).apply(preprocess_text)\n",
    "\n",
    "    corpus = test_news['processed_content'].tolist()\n",
    "    keywords = list(set(key_words_Up+key_words_Down))\n",
    "    count_vectorizer = CountVectorizer(vocabulary=keywords)\n",
    "\n",
    "\n",
    "    tfidf_matrix = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # 將 tfidf_matrix 轉換為 DataFrame\n",
    "    df_wv_space_test = pd.DataFrame(data=tfidf_matrix.toarray(), columns=keywords)\n",
    "    df_wv_space_test = df_wv_space_test.astype(int)\n",
    "    # 顯示結果\n",
    "    print(df_wv_space_test)\n",
    "\n",
    "\n",
    "    #顯示漲跌新聞比例\n",
    "    print('測試新聞-漲跌新聞比例\\n',pd.value_counts(df_wv_space_test.iloc[:,0]))\n",
    "\n",
    "    #加上漲跌標籤\n",
    "    #3天後股價上漲下跌超過2.5%\n",
    "\n",
    "    df_wv_space_test['Ndayaf_sign'] = test_news['Ndayaf_sign'].to_list()\n",
    "\n",
    "\n",
    "    #匯出csv\n",
    "    #df_wv_space_test.to_csv('df_wv_space_test.csv', index=True,encoding='utf-8')\n",
    "    \n",
    "else:\n",
    "    print('no this mode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31c9621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'龐大賣'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_wv_space_test.iloc[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dece681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19     0\n",
       "386    0\n",
       "65     0\n",
       "84     0\n",
       "124    0\n",
       "128    0\n",
       "20     0\n",
       "Name: 靠奈米, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##檢查用\n",
    "#檢查corpus中特定詞彙出現的index\n",
    "test_word_in_corpus = df_wv_space_test.columns[3]\n",
    "contains_search = [test_word_in_corpus in text for text in corpus]\n",
    "\n",
    "# 输出结果\n",
    "#print(contains_search)\n",
    "true_indices = [index for index, value in enumerate(contains_search) if value]\n",
    "\n",
    "# 输出结果\n",
    "print(true_indices)\n",
    "\n",
    "#檢查wv_space有沒有對應到上面的index\n",
    "df_wv_space_test.loc[[19,386, 65, 84, 124, 128, 20],test_word_in_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e980de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###模型建立與資料處裡\n",
    "###拆分資料\n",
    "y_train = df_wv_space_train['Ndayaf_sign']\n",
    "y_test = df_wv_space_test['Ndayaf_sign']\n",
    "X_train = df_wv_space_train.drop('Ndayaf_sign',axis = 1)\n",
    "X_test = df_wv_space_test.drop('Ndayaf_sign',axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea566996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[55  2]\n",
      " [10  3]]\n",
      "done        post_time     Prob     Ndayaf_sign\n",
      "0     2016-01-04      NaN  DOWN2.5percent\n",
      "1     2016-01-04      NaN  DOWN2.5percent\n",
      "2     2016-01-04      NaN  DOWN2.5percent\n",
      "3     2016-01-04      NaN  DOWN2.5percent\n",
      "4     2016-01-05      NaN       UNCHANGED\n",
      "...          ...      ...             ...\n",
      "3371  2018-12-22 250.3721       UNCHANGED\n",
      "3372  2018-12-22 250.3721       UNCHANGED\n",
      "3373  2018-12-22 250.3721       UNCHANGED\n",
      "3374  2018-12-22 250.3721       UNCHANGED\n",
      "3375  2018-12-22 250.3721       UNCHANGED\n",
      "\n",
      "[3376 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\488235730.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['volume_diff'] = specific_stock_price['成交量(千股)'] - specific_stock_price['成交量(千股)'].rolling(5).mean()\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\488235730.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['average_price_5d'] = specific_stock_price['收盤價(元)'].rolling(5).mean()\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\488235730.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['close_price_pct_change'] = (specific_stock_price['收盤價(元)'] - specific_stock_price['收盤價(元)'].rolling(5).mean()) / specific_stock_price['收盤價(元)'].rolling(5).mean()\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\488235730.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['volume_pct_change'] = (specific_stock_price['成交量(千股)'] - specific_stock_price['成交量(千股)'].rolling(5).mean()) / specific_stock_price['成交量(千股)'].rolling(5).mean()\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\488235730.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['close_price_pct_change_prev_day'] = specific_stock_price['收盤價(元)'].pct_change()\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\488235730.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['short_ma_close'] = specific_stock_price['收盤價(元)'].rolling(window=10).mean()\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\488235730.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['medium_ma_close'] = specific_stock_price['收盤價(元)'].rolling(window=20).mean()\n",
      "C:\\Users\\shawn\\AppData\\Local\\Temp\\ipykernel_28352\\488235730.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['long_ma_close'] = specific_stock_price['收盤價(元)'].rolling(window=40).mean()\n"
     ]
    }
   ],
   "source": [
    "##利用股價資料與衍生指標計算漲跌機率值，再將預測機率作為變數放入後續模型\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 假設數據框名稱為 data\n",
    "# 選取需要的特徵\n",
    "features = ['開盤價(元)', '最高價(元)', '最低價(元)', '收盤價(元)', '成交量(千股)', '成交值(千元)', '成交筆數(筆)', '流通在外股數(千股)']\n",
    "\n",
    "# 選取目標變數\n",
    "target = '3dayaf_sign'\n",
    "\n",
    "# 创建 XGBoost 分类器\n",
    "# 創建特徵矩陣 X 和目標變數 y\n",
    "X = specific_stock_price[features]\n",
    "y = specific_stock_price[target]\n",
    "\n",
    "# 新增特徵\n",
    "X['volume_diff'] = specific_stock_price['成交量(千股)'] - specific_stock_price['成交量(千股)'].rolling(5).mean()\n",
    "X['average_price_5d'] = specific_stock_price['收盤價(元)'].rolling(5).mean()\n",
    "X['close_price_pct_change'] = (specific_stock_price['收盤價(元)'] - specific_stock_price['收盤價(元)'].rolling(5).mean()) / specific_stock_price['收盤價(元)'].rolling(5).mean()\n",
    "X['volume_pct_change'] = (specific_stock_price['成交量(千股)'] - specific_stock_price['成交量(千股)'].rolling(5).mean()) / specific_stock_price['成交量(千股)'].rolling(5).mean()\n",
    "X['close_price_pct_change_prev_day'] = specific_stock_price['收盤價(元)'].pct_change()\n",
    "\n",
    "\n",
    "# Additional derived indicators\n",
    "X['short_ma_close'] = specific_stock_price['收盤價(元)'].rolling(window=10).mean()\n",
    "X['medium_ma_close'] = specific_stock_price['收盤價(元)'].rolling(window=20).mean()\n",
    "X['long_ma_close'] = specific_stock_price['收盤價(元)'].rolling(window=40).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 去除包含空值的行\n",
    "X = X.reset_index(drop=True).dropna()\n",
    "\n",
    "y = y.reset_index(drop=True)[X.index]  # 确保目标变量与特征对应\n",
    "\n",
    "\n",
    "##利用logistic regression 賦予每天漲超過 特定幅度 的機率\n",
    "##訓練測試區\n",
    "# instantiate the model (using the default parameters)\n",
    "\n",
    "y_logistic = [0 if y == 'UNCHANGED' else 1 if y == 'UP{}percent'.format(percentage_threshold * 100) else 0 for y in y]\n",
    "# 將數據分為訓練集和測試集\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y_logistic, test_size=0.1, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "\n",
    "\n",
    "# 正規化特徵矩陣 X\n",
    "scaler = StandardScaler()\n",
    "Xtrain1_normalized = scaler.fit_transform(X_train_1)\n",
    "Xtrain1_normalized = pd.DataFrame(Xtrain1_normalized, columns=X_train_1.columns)\n",
    "\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(Xtrain1_normalized, y_train_1)\n",
    "\n",
    "# 正規化特徵矩陣 X\n",
    "scaler = StandardScaler()\n",
    "Xtest1_normalized = scaler.fit_transform(X_test_1)\n",
    "Xtest1_normalized = pd.DataFrame(Xtest1_normalized, columns=X_test_1.columns)\n",
    "\n",
    "\n",
    "y_pred_logistic = logreg.predict_proba(Xtest1_normalized)\n",
    "y_pred_logistic = y_pred_logistic[:, 1]\n",
    "\n",
    "# Assuming y_probabilities_class_1 contains the predicted probabilities for class 1\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_binary = np.where(y_pred_logistic > 0.23, 1, 0)\n",
    "\n",
    "# Assuming y_test contains the true labels for your test set\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_1, y_pred_binary)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "\n",
    "##全訓練 重新餵入詞向量model\n",
    "#找出如何對上新聞的日期\n",
    "# instantiate the model (using the default parameters)\n",
    "\n",
    "y_logistic = [0 if y == 'UNCHANGED' else 1 if y == 'UP{}percent'.format(percentage_threshold * 100) else 0 for y in y]\n",
    "# 將數據分為訓練集和測試集\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X, y_logistic)\n",
    "\n",
    "#獲得預測機率\n",
    "y_pred_logistic = logreg.predict_proba(X)\n",
    "y_pred_logistic = y_pred_logistic[:, 1]\n",
    "\n",
    "\n",
    "#將日期與預測機率值合併\n",
    "y_pred_logistic_prob = pd.DataFrame({'年月日':specific_stock_price.reset_index(drop = True).loc[X.index,'年月日'], 'Prob': y_pred_logistic})\n",
    "\n",
    "\n",
    "#將合併後的日期與預測機率值 再分別與訓練與測試新聞集合併\n",
    "logistic_prob_for_train_news =  pd.merge(train_news,y_pred_logistic_prob,left_on= 'post_time',right_on = '年月日', how = 'left')[['post_time','Prob','Ndayaf_sign']]\n",
    "logistic_prob_for_train_news['Prob'] = (logistic_prob_for_train_news['Prob']*100)**2\n",
    "logistic_prob_for_train_news.head()\n",
    "logistic_prob_for_test_news =  pd.merge(test_news,y_pred_logistic_prob,left_on= 'post_time',right_on = '年月日', how = 'left')[['post_time','Prob','Ndayaf_sign']]\n",
    "logistic_prob_for_test_news['Prob'] = (logistic_prob_for_test_news['Prob']*100)**2\n",
    "logistic_prob_for_test_news.head()\n",
    "\n",
    "print('done',logistic_prob_for_test_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eeb1a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.873\n",
      "recall_score: 0.873\n",
      "precision_score: 0.873\n",
      "Confusion Matrix:\n",
      "                     Predicted UP2percent  Predicted DOWN2percent  \\\n",
      "Actual UP2percent                     238                       0   \n",
      "Actual DOWN2percent                     1                      61   \n",
      "Actual UNCHANGED                       55                      10   \n",
      "\n",
      "                     Predicted UNCHANGED  \n",
      "Actual UP2percent                    275  \n",
      "Actual DOWN2percent                   75  \n",
      "Actual UNCHANGED                    2567  \n"
     ]
    }
   ],
   "source": [
    "###Model 3 with logistic prob.\n",
    "class_weights = {'UP{}percent'.format(percentage_threshold*100): 0.7, 'UP{}percent'.format(percentage_threshold*100): 0.2,\n",
    "                'UNCHANGED':0.1}\n",
    "\n",
    "\n",
    "y_pred_logistic\n",
    "# Instantiate the random forest classifier with key parameters\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    #class_weight = class_weights\n",
    ")\n",
    "\n",
    "\n",
    "#train with prob\n",
    "X_train_with_prob = X_train\n",
    "X_train_with_prob['Prob'] = logistic_prob_for_train_news['Prob']\n",
    "y_train_with_prob = y_train.loc[X_train_with_prob['Prob'].isna()==False]\n",
    "X_train_with_prob = X_train_with_prob.loc[X_train_with_prob['Prob'].isna()==False,:]\n",
    "\n",
    "clf_rf.fit(X_train_with_prob, y_train_with_prob)\n",
    "\n",
    "#train only by word vector\n",
    "#clf_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 预测\n",
    "#test with prob\n",
    "X_test_with_prob = X_test\n",
    "X_test_with_prob['Prob'] = logistic_prob_for_test_news['Prob']\n",
    "y_test_with_prob = y_test.loc[X_test_with_prob['Prob'].isna()==False]\n",
    "X_test_with_prob = X_test_with_prob.loc[X_test_with_prob['Prob'].isna()==False,:]\n",
    "\n",
    "\n",
    "y_pred3 = clf_rf.predict(X_test_with_prob)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the performance on the test set to compare\n",
    "\n",
    "print('accuracy_score: {:.3f}'.format(accuracy_score(y_test_with_prob, y_pred3)))\n",
    "print('recall_score: {:.3f}'.format(recall_score(y_test_with_prob, y_pred3, average='micro')))\n",
    "print('precision_score: {:.3f}'.format(precision_score(y_test_with_prob, y_pred3, average='micro')))\n",
    "\n",
    "\n",
    "#三維\n",
    "# 計算混淆矩陣\n",
    "conf_matrix = confusion_matrix(y_test_with_prob, y_pred3, labels=['UP{}percent'.format(percentage_threshold*100), 'DOWN{}percent'.format(percentage_threshold*100), 'UNCHANGED'])\n",
    "\n",
    "index_names = ['Actual UP2percent', 'Actual DOWN2percent', 'Actual UNCHANGED']\n",
    "column_names = ['Predicted UP2percent', 'Predicted DOWN2percent', 'Predicted UNCHANGED']\n",
    "\n",
    "# 將混淆矩陣包裝在 DataFrame 中\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=index_names, columns=column_names)\n",
    "\n",
    "# 打印混淆矩陣\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_df)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e207d125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "起始日期: 2016-01-04 終止日期: 2018-12-22 有效日數: 732\n",
      "UNCHANGED         666\n",
      "UP2.5percent       44\n",
      "DOWN2.5percent     22\n",
      "Name: final_predict_sign, dtype: int64\n",
      "\n",
      "出手率(漲) effective_ratio:\n",
      " 6.01%\n",
      "Confusion Matrix:\n",
      "                  Predicted UP  Predicted DOWN  Predicted UNCHANGED\n",
      "Actual UP                   37               0                   78\n",
      "Actual DOWN                  0              12                   12\n",
      "Actual UNCHANGED             7              10                  576\n",
      "\n",
      "如有出手的指標\n",
      "Accuracy: 0.7424242424242424\n",
      "\n",
      "Precision: 0.8409090909090909\n",
      "\n",
      "Recall: 0.3217391304347826\n"
     ]
    }
   ],
   "source": [
    "#將預測轉為日期維度\n",
    "y_pred = y_pred3\n",
    "\n",
    "date_prediction = pd.DataFrame(logistic_prob_for_test_news[logistic_prob_for_test_news['Prob'].isna()==False]['post_time'].to_list(),y_pred).reset_index(drop=False)\n",
    "date_prediction.loc[date_prediction.loc[:,'index'].str.contains('UP'),'predict_sign_sum'] = 1\n",
    "date_prediction.loc[date_prediction.loc[:,'index'].str.contains('UNCHANGED'),'predict_sign_sum'] = 0\n",
    "date_prediction.loc[date_prediction.loc[:,'index'].str.contains('DOWN'),'predict_sign_sum'] = -1\n",
    "date_prediction.rename(columns={'index': 'Prediction'}, inplace=True)\n",
    "date_prediction.rename(columns={0: 'Date'}, inplace=True)\n",
    "date_prediction.head()\n",
    "\n",
    "# 將整天的新聞預測合併，觀察是預測漲的新聞多、跌的新聞多，還是不變的新聞多\n",
    "date_prediction_gb = date_prediction.groupby(by = 'Date')['predict_sign_sum'].sum()\n",
    "label =  specific_stock_price.loc[specific_stock_price['年月日']>=min(test_news['年月日']) ,['年月日','{}dayaf_sign'.format(N_days_after)]] #真正股價指標\n",
    "date_prediction_gb = pd.merge(date_prediction_gb,label, left_on = 'Date', right_on = '年月日' ,how = 'right')\n",
    "date_prediction_gb = date_prediction_gb.iloc[:,[1,0,2]]\n",
    "\n",
    "date_prediction_gb['predict_sign_sum'] = date_prediction_gb['predict_sign_sum'].fillna(0)\n",
    "date_prediction_gb.loc[date_prediction_gb['predict_sign_sum']>=2,'final_predict_sign'] = 'UP{}percent'.format(percentage_threshold*100)\n",
    "date_prediction_gb.loc[(date_prediction_gb['predict_sign_sum']>=0)&(date_prediction_gb['predict_sign_sum']<=1),'final_predict_sign'] = 'UNCHANGED'\n",
    "date_prediction_gb.loc[date_prediction_gb['predict_sign_sum']<=-1,'final_predict_sign'] = 'DOWN{}percent'.format(percentage_threshold*100)\n",
    "date_prediction_gb.head()\n",
    "\n",
    "\n",
    "##計算各觀測指標\n",
    "print('起始日期:',min(date_prediction_gb['年月日']),'終止日期:',max(date_prediction_gb['年月日']),\n",
    "      '有效日數:',len(date_prediction_gb))\n",
    "print(pd.value_counts(date_prediction_gb['final_predict_sign']))\n",
    "effective_sign_1 = pd.value_counts(date_prediction_gb['final_predict_sign']).get(1, 0)  # UP\n",
    "effective_sign_2 = pd.value_counts(date_prediction_gb['final_predict_sign']).get(2, 0)  # DOWN\n",
    "noneffective_sign = pd.value_counts(date_prediction_gb['final_predict_sign']).get(0, 0)  # UNCHANGED\n",
    "\n",
    "effective_ratio = (effective_sign_1 ) / (effective_sign_1 + effective_sign_2 + noneffective_sign)\n",
    "print('\\n出手率(漲) effective_ratio:\\n','{:.2f}%'.format(effective_ratio*100))\n",
    "\n",
    "\n",
    "# 計算出手混淆矩陣\n",
    "conf_matrix = confusion_matrix(date_prediction_gb['{}dayaf_sign'.format(N_days_after)],date_prediction_gb['final_predict_sign'], \n",
    "                               labels=['UP{}percent'.format(percentage_threshold*100), \n",
    "                                       'DOWN{}percent'.format(percentage_threshold*100), 'UNCHANGED'])\n",
    "\n",
    "index_names = ['Actual UP', 'Actual DOWN', 'Actual UNCHANGED']\n",
    "column_names = ['Predicted UP', 'Predicted DOWN', 'Predicted UNCHANGED']\n",
    "\n",
    "# 將混淆矩陣包裝在 DataFrame 中\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=index_names, columns=column_names)\n",
    "\n",
    "# 打印混淆矩陣\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_df)\n",
    "\n",
    "#如有出手的指標\n",
    "Accuracy = (confusion_df.iloc[0,0] + confusion_df.iloc[1,1]) / confusion_df.iloc[:,[0,1]].sum().sum()\n",
    "print('')\n",
    "print('如有出手的指標')\n",
    "print('Accuracy:',Accuracy)\n",
    "\n",
    "Precision = confusion_df.iloc[0,0]  / (confusion_df.iloc[0,0] + confusion_df.iloc[1,0]+ confusion_df.iloc[2,0])\n",
    "print('')\n",
    "print('Precision:',Precision)\n",
    "\n",
    "Recall = confusion_df.iloc[0,0]  / (confusion_df.iloc[0,0] + confusion_df.iloc[0,1] +  confusion_df.iloc[0,2])\n",
    "print('')\n",
    "print('Recall:',Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89abef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算獲利\n",
    "# 每次購買N張股票\n",
    "def profit_calculator(df,N):\n",
    "    profit_df = []\n",
    "    cost_df = []\n",
    "    revenue_df = []\n",
    "    for i in range(0,len(df),1):\n",
    "        if df.loc[i]['final_predict_sign'] == 'UP{}percent'.format(percentage_threshold*100):\n",
    "            profit = (df.loc[i]['{}dayaf_high'.format(N_days_after)]- df.loc[i]['開盤價(元)'])*1000*N\n",
    "            revenue = df.loc[i]['{}dayaf_high'.format(N_days_after)]*1000*N\n",
    "            cost = df.loc[i]['開盤價(元)']*1000*N\n",
    "        else:\n",
    "            profit = 0\n",
    "            revenue = 0\n",
    "            cost = 0\n",
    "            \n",
    "        profit_df.append(profit)\n",
    "        cost_df.append(cost)\n",
    "        revenue_df.append(revenue)\n",
    "    \n",
    "    profit_df = np.array(profit_df)\n",
    "    cost_df = np.array(cost_df)\n",
    "    revenue_df = np.array(revenue_df)\n",
    "        \n",
    "    profit_sum = sum(profit_df)\n",
    "    cost_sum = sum(cost_df)\n",
    "    revenue_sum = sum(revenue_df)\n",
    "    \n",
    "    \n",
    "    df_wrong_predict = (df.loc[(df['{}dayaf_sign_y'.format(N_days_after)] != 'UP{}percent'.format(percentage_threshold*100)) & (df['final_predict_sign'] == 'UP{}percent'.format(percentage_threshold*100))]['{}dayaf_high'.format(N_days_after)] - df.loc[(df['{}dayaf_sign_y'.format(N_days_after)] != 'UP{}percent'.format(percentage_threshold*100)) & (df['final_predict_sign'] == 'UP{}percent'.format(percentage_threshold*100))]['開盤價(元)']) * 1000 * N\n",
    "    \n",
    "    # Assuming cost_sum, profit_sum, and revenue_sum are your numeric values\n",
    "    cost_sum_formatted = '{:,.0f}'.format(cost_sum)\n",
    "    profit_sum_formatted = '{:,.0f}'.format(profit_sum)\n",
    "    revenue_sum_formatted = '{:,.0f}'.format(revenue_sum)\n",
    "    test_news_date = set(test_news['年月日'].reset_index(drop = True)[X_test_with_prob.index])\n",
    "    \n",
    "    report = {\n",
    "        '預測股票 : ' : stock_want_to_predict,\n",
    "        '資料集新聞篇數 : ' : len(df_wv_space_test) + len(df_wv_space_train),\n",
    "        '資料集起始日期:': min(date_prediction_gb['年月日']),\n",
    "        '資料集終止日期:' : max(date_prediction_gb['年月日']),\n",
    "        '資料集有效日數:': len(date_prediction_gb),\n",
    "        '\\n測試新聞篇數 : ' : len(df_wv_space_test),\n",
    "        '測試新聞起始日期:終止日期 :' : ((min(test_news_date))+ ' : ' + (max(test_news_date))), \n",
    "        '測試新聞有效日數:': len(test_news_date ),\n",
    "        '-----------' : '-----------------------------',\n",
    "        '總獲利(不考慮手續費與稅): $' : profit_sum_formatted,\n",
    "        '總收入(不考慮手續費與稅): $' : revenue_sum_formatted,\n",
    "        '總成本(不考慮手續費與稅): $' : cost_sum_formatted,\n",
    "        'ROI : ' : '{:.2f}%'.format(round((revenue_sum - cost_sum)/cost_sum,4)*100) ,\n",
    "        \"\\n平均單次成本 : $\" : '{:,.0f}'.format(round(np.mean(cost_sum/len(cost_df[cost_df!=0])),0)), \n",
    "        '出手次數 : ' : len(cost_df[cost_df!=0]),\n",
    "        '每次購買張數 : ' : N,\n",
    "        '\\n預測成功時平均賺 : $' :  '{:,.0f}'.format(round(np.mean(cost_df[cost_df>=0]),0)),\n",
    "        '預測失敗時平均賺賠 : $' :  '{:,.0f}'.format(round(np.mean(df_wrong_predict),0)),\n",
    "        '預測成功次數 : ' : confusion_df.iloc[0,0],\n",
    "        '預測失敗次數 : ' : confusion_df.iloc[1,0] + confusion_df.iloc[2,0]      \n",
    "    }\n",
    "    \n",
    "    for key, value in report.items():\n",
    "        print(f\"{key}{value}\")\n",
    "df = pd.merge(date_prediction_gb,specific_stock_price, left_on= '年月日',right_on= '年月日', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "508ac460",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測股票 : 台積電\n",
      "資料集新聞篇數 : 16878\n",
      "資料集起始日期:2016-01-04\n",
      "資料集終止日期:2018-12-22\n",
      "資料集有效日數:732\n",
      "\n",
      "測試新聞篇數 : 3376\n",
      "測試新聞起始日期:終止日期 :2016-03-08 : 2018-12-22\n",
      "測試新聞有效日數:655\n",
      "----------------------------------------\n",
      "總獲利(不考慮手續費與稅): $719,500\n",
      "總收入(不考慮手續費與稅): $19,134,520\n",
      "總成本(不考慮手續費與稅): $18,415,020\n",
      "ROI : 3.91%\n",
      "\n",
      "平均單次成本 : $418,523\n",
      "出手次數 : 44\n",
      "每次購買張數 : 2\n",
      "\n",
      "預測成功時平均賺 : $25,157\n",
      "預測失敗時平均賺賠 : $4,791\n",
      "預測成功次數 : 37\n",
      "預測失敗次數 : 7\n"
     ]
    }
   ],
   "source": [
    "# Fianl Report\n",
    "profit_calculator(df,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
